{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uzVrpwJkK1Tf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "# import seaborn as sns\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import font_manager, rc\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import keras\n",
    "import sklearn\n",
    "\n",
    "# 데이터 분할 함수 : 6.2.2\n",
    "def split(data_x, data_y):\n",
    "    train_size = int(len(data_x)*0.6)\n",
    "    val_size = int(len(data_x)*0.8)\n",
    "    \n",
    "    data_train_x = data_x[:train_size]\n",
    "    data_val_x = data_x[train_size:val_size]\n",
    "    data_test_x = data_x[val_size:]\n",
    "    \n",
    "    data_train_y = data_y[:train_size]\n",
    "    data_val_y = data_y[train_size:val_size]\n",
    "    data_test_y = data_y[val_size:] \n",
    "    \n",
    "    return data_train_x, data_val_x, data_test_x, data_train_y, data_val_y, data_test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JHZi56eewSr"
   },
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "9sorSai6ekMG",
    "outputId": "c30f7e09-ae3d-4d61-d7f6-ad70bc3f9e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (998, 8) (998,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.195497</td>\n",
       "      <td>0.477161</td>\n",
       "      <td>0.050592</td>\n",
       "      <td>0.692142</td>\n",
       "      <td>0.153196</td>\n",
       "      <td>0.341791</td>\n",
       "      <td>0.781347</td>\n",
       "      <td>0.090310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.497016</td>\n",
       "      <td>0.063101</td>\n",
       "      <td>0.541688</td>\n",
       "      <td>0.176717</td>\n",
       "      <td>0.217213</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.083032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.492984</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.981248</td>\n",
       "      <td>0.300592</td>\n",
       "      <td>0.255252</td>\n",
       "      <td>0.551081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.050787</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.140953</td>\n",
       "      <td>0.466094</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.236625</td>\n",
       "      <td>0.161825</td>\n",
       "      <td>0.667478</td>\n",
       "      <td>0.078551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.125894</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.370823</td>\n",
       "      <td>0.432237</td>\n",
       "      <td>0.035037</td>\n",
       "      <td>0.900781</td>\n",
       "      <td>0.151271</td>\n",
       "      <td>0.494509</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>0.134021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.371602</td>\n",
       "      <td>0.075812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.716249</td>\n",
       "      <td>0.577903</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.934970</td>\n",
       "      <td>0.322444</td>\n",
       "      <td>0.251729</td>\n",
       "      <td>0.400836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0.236220</td>\n",
       "      <td>0.262876</td>\n",
       "      <td>0.101083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      culture    build1    build2    build3    build4    build5    build6  \\\n",
       "743  0.195497  0.477161  0.050592  0.692142  0.153196  0.341791  0.781347   \n",
       "583  0.100968  0.497016  0.063101  0.541688  0.176717  0.217213  0.726333   \n",
       "567  0.912409  0.492984  0.066667  0.074074  0.981248  0.300592  0.255252   \n",
       "262  0.087591  0.377778  0.057143  0.222222  0.149425  0.157480  0.050787   \n",
       "853  0.140953  0.466094  0.069952  0.481481  0.236625  0.161825  0.667478   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "381  0.021898  0.644444  0.152381  0.000000  0.114943  0.039370  0.125894   \n",
       "580  0.370823  0.432237  0.035037  0.900781  0.151271  0.494509  0.993684   \n",
       "33   0.153285  0.327778  0.152381  0.407407  0.091954  0.259843  0.371602   \n",
       "686  0.716249  0.577903  0.080137  0.021688  0.934970  0.322444  0.251729   \n",
       "410  0.043796  0.616667  0.076190  0.074074  0.057471  0.236220  0.262876   \n",
       "\n",
       "       build7  label  \n",
       "743  0.090310      1  \n",
       "583  0.083032      1  \n",
       "567  0.551081      1  \n",
       "262  0.036101      0  \n",
       "853  0.078551      1  \n",
       "..        ...    ...  \n",
       "381  0.061372      0  \n",
       "580  0.134021      1  \n",
       "33   0.075812      0  \n",
       "686  0.400836      1  \n",
       "410  0.101083      0  \n",
       "\n",
       "[998 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 군집화\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\군집화_결과.csv\",  header=0, squeeze=True)\n",
    "X = df.iloc[:, 1:-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X, Y = smote.fit_resample(X.values, Y.values)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X.shape, Y.shape)\n",
    "\n",
    "data = pd.DataFrame(X, columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "data['label'] = Y\n",
    "\n",
    "df_shuffled=sklearn.utils.shuffle(data, random_state=555)\n",
    "X = df_shuffled.iloc[:, :-1]\n",
    "Y = df_shuffled.iloc[:, -1]\n",
    "\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1mMJ8kTc4dz"
   },
   "source": [
    "# 6:2:2 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 200 200 598 200 200 (598, 8)\n"
     ]
    }
   ],
   "source": [
    "search_train_x, search_val_x, search_test_x, search_train_y, search_val_y, search_test_y = split(X, Y)\n",
    "print(len(search_train_x), len(search_val_x), len(search_test_x), len(search_train_y), len(search_val_x), len(search_test_y), search_train_x.shape)\n",
    "#-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.5899999737739563\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 00m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 16, 32 and the optimal learning rate for the optimizer\n",
      "is 0.01.\n"
     ]
    }
   ],
   "source": [
    "# !pip install IPython\n",
    "# !pip install -q -U keras-tuner\n",
    "import kerastuner as kt\n",
    "import IPython\n",
    "\n",
    "tf.random.set_seed(555)\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "\n",
    "def model_builder(hp):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(search_train_x.shape[1],)))\n",
    "\n",
    "    hp_units1 = hp.Int('units1', min_value = 8 , max_value = 32, step = 8)\n",
    "    hp_units2 = hp.Int('units2', min_value = 8, max_value = 32, step = 8)\n",
    "    model.add(keras.layers.Dense(units = hp_units1, activation = 'relu'))\n",
    "    model.add(layers.Dense(units = hp_units2, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate), \n",
    "                  loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 2,\n",
    "                     overwrite=True,\n",
    "                     seed = 0)\n",
    "\n",
    "tuner.search(search_train_x, search_train_y, epochs=10, batch_size=10,\n",
    "                 callbacks=[ClearTrainingOutput()], validation_data=(search_val_x, search_val_y))\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# 최적의 파라미터 값 저장\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units1')}, {best_hps.get('units2')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2yEK6P-djmy"
   },
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ptn6U-s2Yz52",
    "outputId": "34a1a00f-61ce-4a56-e036-7448dfad879c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.6706 - val_loss: 0.4050 - val_accuracy: 0.9150\n",
      "Epoch 2/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.9749 - val_loss: 0.2108 - val_accuracy: 0.9950\n",
      "Epoch 3/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9916 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 4/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9933 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 5/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9983 - val_loss: 0.0238 - val_accuracy: 1.0000\n",
      "Epoch 6/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9967 - val_loss: 0.0359 - val_accuracy: 0.9850\n",
      "Epoch 7/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.7363e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.6440e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.1455e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.5735e-04 - accuracy: 1.0000 - val_loss: 8.7516e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.8307e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.5431e-04 - accuracy: 1.0000 - val_loss: 9.0911e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.6578e-04 - accuracy: 1.0000 - val_loss: 7.1687e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.2249e-04 - accuracy: 1.0000 - val_loss: 6.8984e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.4907e-04 - accuracy: 1.0000 - val_loss: 4.3083e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.7610e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.2420e-04 - accuracy: 1.0000 - val_loss: 3.2814e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.6368e-04 - accuracy: 1.0000 - val_loss: 3.9417e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.9516e-04 - accuracy: 1.0000 - val_loss: 4.0734e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.7642e-04 - accuracy: 1.0000 - val_loss: 6.5056e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.1851e-04 - accuracy: 1.0000 - val_loss: 2.7610e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.2265e-04 - accuracy: 1.0000 - val_loss: 3.3451e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.7913e-04 - accuracy: 1.0000 - val_loss: 4.2754e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0818e-04 - accuracy: 1.0000 - val_loss: 4.6277e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.4672e-04 - accuracy: 1.0000 - val_loss: 2.6307e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.1949e-04 - accuracy: 1.0000 - val_loss: 3.2548e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0766e-04 - accuracy: 1.0000 - val_loss: 2.6086e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.7466e-04 - accuracy: 1.0000 - val_loss: 2.2580e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.7486e-04 - accuracy: 1.0000 - val_loss: 3.1804e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0128e-04 - accuracy: 1.0000 - val_loss: 4.4480e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.4082e-04 - accuracy: 1.0000 - val_loss: 1.3659e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1574e-04 - accuracy: 1.0000 - val_loss: 1.9355e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1625e-04 - accuracy: 1.0000 - val_loss: 1.5052e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0298e-04 - accuracy: 1.0000 - val_loss: 2.3128e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8367e-04 - accuracy: 1.0000 - val_loss: 1.0938e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8169e-04 - accuracy: 1.0000 - val_loss: 2.0806e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7125e-04 - accuracy: 1.0000 - val_loss: 1.1948e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.7139e-04 - accuracy: 1.0000 - val_loss: 9.4303e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.6078e-04 - accuracy: 1.0000 - val_loss: 1.6693e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4611e-04 - accuracy: 1.0000 - val_loss: 1.4231e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3917e-04 - accuracy: 1.0000 - val_loss: 1.1571e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3726e-04 - accuracy: 1.0000 - val_loss: 9.5394e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2994e-04 - accuracy: 1.0000 - val_loss: 8.3967e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2634e-04 - accuracy: 1.0000 - val_loss: 1.0314e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1403e-04 - accuracy: 1.0000 - val_loss: 1.1112e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0746e-04 - accuracy: 1.0000 - val_loss: 6.2351e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1239e-04 - accuracy: 1.0000 - val_loss: 1.0892e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.9871e-05 - accuracy: 1.0000 - val_loss: 8.5502e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.7252e-05 - accuracy: 1.0000 - val_loss: 7.6758e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.7788e-05 - accuracy: 1.0000 - val_loss: 7.1546e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.8764e-05 - accuracy: 1.0000 - val_loss: 7.1265e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.5139e-05 - accuracy: 1.0000 - val_loss: 1.0671e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.8508e-05 - accuracy: 1.0000 - val_loss: 4.1662e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 8.4941e-05 - accuracy: 1.0000 - val_loss: 9.2745e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.7894e-05 - accuracy: 1.0000 - val_loss: 5.3040e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.9162e-05 - accuracy: 1.0000 - val_loss: 4.4893e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.7432e-05 - accuracy: 1.0000 - val_loss: 5.7972e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.3814e-05 - accuracy: 1.0000 - val_loss: 6.2507e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.1387e-05 - accuracy: 1.0000 - val_loss: 5.3384e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.9309e-05 - accuracy: 1.0000 - val_loss: 4.2648e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.5302e-05 - accuracy: 1.0000 - val_loss: 4.4199e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.3279e-05 - accuracy: 1.0000 - val_loss: 6.1392e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.3781e-05 - accuracy: 1.0000 - val_loss: 5.7116e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.3002e-05 - accuracy: 1.0000 - val_loss: 5.6625e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.3893e-05 - accuracy: 1.0000 - val_loss: 3.2516e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.6185e-05 - accuracy: 1.0000 - val_loss: 6.7333e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.2896e-05 - accuracy: 1.0000 - val_loss: 4.0612e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.9229e-05 - accuracy: 1.0000 - val_loss: 3.4018e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.8307e-05 - accuracy: 1.0000 - val_loss: 3.2363e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.9641e-05 - accuracy: 1.0000 - val_loss: 3.1892e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.5560e-05 - accuracy: 1.0000 - val_loss: 3.3876e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.6110e-05 - accuracy: 1.0000 - val_loss: 2.2237e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.6558e-05 - accuracy: 1.0000 - val_loss: 2.6973e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.4517e-05 - accuracy: 1.0000 - val_loss: 4.7001e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9658e-05 - accuracy: 1.0000 - val_loss: 2.4766e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0309e-05 - accuracy: 1.0000 - val_loss: 3.9738e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9487e-05 - accuracy: 1.0000 - val_loss: 3.3484e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.6870e-05 - accuracy: 1.0000 - val_loss: 2.2334e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.7125e-05 - accuracy: 1.0000 - val_loss: 1.7418e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.8327e-05 - accuracy: 1.0000 - val_loss: 3.5490e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2952e-05 - accuracy: 1.0000 - val_loss: 1.6920e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2667e-05 - accuracy: 1.0000 - val_loss: 2.1229e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.3621e-05 - accuracy: 1.0000 - val_loss: 1.4791e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1270e-05 - accuracy: 1.0000 - val_loss: 1.9592e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9490e-05 - accuracy: 1.0000 - val_loss: 1.4654e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0314e-05 - accuracy: 1.0000 - val_loss: 2.2540e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8363e-05 - accuracy: 1.0000 - val_loss: 1.6495e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7931e-05 - accuracy: 1.0000 - val_loss: 1.7312e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7439e-05 - accuracy: 1.0000 - val_loss: 1.6046e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6734e-05 - accuracy: 1.0000 - val_loss: 1.8292e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6007e-05 - accuracy: 1.0000 - val_loss: 1.7290e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5104e-05 - accuracy: 1.0000 - val_loss: 1.5038e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7470e-05 - accuracy: 1.0000 - val_loss: 1.6075e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4719e-05 - accuracy: 1.0000 - val_loss: 1.7530e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5331e-05 - accuracy: 1.0000 - val_loss: 2.1609e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6324e-05 - accuracy: 1.0000 - val_loss: 1.4592e-05 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4519e-05 - accuracy: 1.0000 - val_loss: 1.7329e-05 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2414e-05 - accuracy: 1.0000 - val_loss: 8.6879e-06 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1002e-05 - accuracy: 1.0000 - val_loss: 1.4619e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1203e-05 - accuracy: 1.0000 - val_loss: 9.6911e-06 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0689e-05 - accuracy: 1.0000 - val_loss: 1.1632e-05 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0232e-05 - accuracy: 1.0000 - val_loss: 1.0001e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.6430e-06 - accuracy: 1.0000 - val_loss: 8.4004e-06 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.3526e-06 - accuracy: 1.0000 - val_loss: 7.6657e-06 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.3628e-06 - accuracy: 1.0000 - val_loss: 1.2219e-05 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.7561e-06 - accuracy: 1.0000 - val_loss: 7.7998e-06 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.2193e-06 - accuracy: 1.0000 - val_loss: 9.9225e-06 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.7019e-06 - accuracy: 1.0000 - val_loss: 5.6890e-06 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.4177e-06 - accuracy: 1.0000 - val_loss: 9.0110e-06 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.7056e-06 - accuracy: 1.0000 - val_loss: 9.9514e-06 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.8451e-06 - accuracy: 1.0000 - val_loss: 7.1156e-06 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.9837e-06 - accuracy: 1.0000 - val_loss: 7.6287e-06 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.7959e-06 - accuracy: 1.0000 - val_loss: 6.9991e-06 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.5636e-06 - accuracy: 1.0000 - val_loss: 6.9907e-06 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.4371e-06 - accuracy: 1.0000 - val_loss: 5.5584e-06 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.6197e-06 - accuracy: 1.0000 - val_loss: 6.2565e-06 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.1620e-06 - accuracy: 1.0000 - val_loss: 5.6044e-06 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.8701e-06 - accuracy: 1.0000 - val_loss: 7.5245e-06 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 5.8800e-06 - accuracy: 1.0000 - val_loss: 6.5327e-06 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.4969e-06 - accuracy: 1.0000 - val_loss: 4.5811e-06 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.0850e-06 - accuracy: 1.0000 - val_loss: 5.8487e-06 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.3212e-06 - accuracy: 1.0000 - val_loss: 5.0849e-06 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.8577e-06 - accuracy: 1.0000 - val_loss: 4.3517e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.4603e-06 - accuracy: 1.0000 - val_loss: 3.7100e-06 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.5638e-06 - accuracy: 1.0000 - val_loss: 3.9913e-06 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.3730e-06 - accuracy: 1.0000 - val_loss: 4.8753e-06 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.5580e-06 - accuracy: 1.0000 - val_loss: 5.4250e-06 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0780e-06 - accuracy: 1.0000 - val_loss: 4.0650e-06 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0859e-06 - accuracy: 1.0000 - val_loss: 4.9878e-06 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.8232e-06 - accuracy: 1.0000 - val_loss: 3.3459e-06 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.7357e-06 - accuracy: 1.0000 - val_loss: 5.1753e-06 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.5324e-06 - accuracy: 1.0000 - val_loss: 3.4010e-06 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.3578e-06 - accuracy: 1.0000 - val_loss: 3.6791e-06 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.2400e-06 - accuracy: 1.0000 - val_loss: 3.3143e-06 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0959e-06 - accuracy: 1.0000 - val_loss: 3.2938e-06 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9811e-06 - accuracy: 1.0000 - val_loss: 3.0775e-06 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9527e-06 - accuracy: 1.0000 - val_loss: 2.5369e-06 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.7352e-06 - accuracy: 1.0000 - val_loss: 2.3812e-06 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.6661e-06 - accuracy: 1.0000 - val_loss: 2.6392e-06 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.5342e-06 - accuracy: 1.0000 - val_loss: 2.7670e-06 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.5155e-06 - accuracy: 1.0000 - val_loss: 1.8568e-06 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4629e-06 - accuracy: 1.0000 - val_loss: 2.2644e-06 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4368e-06 - accuracy: 1.0000 - val_loss: 2.1651e-06 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2554e-06 - accuracy: 1.0000 - val_loss: 2.1645e-06 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1819e-06 - accuracy: 1.0000 - val_loss: 2.1923e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1257e-06 - accuracy: 1.0000 - val_loss: 2.8393e-06 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9918e-06 - accuracy: 1.0000 - val_loss: 1.8339e-06 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9267e-06 - accuracy: 1.0000 - val_loss: 1.5714e-06 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9404e-06 - accuracy: 1.0000 - val_loss: 1.5762e-06 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8799e-06 - accuracy: 1.0000 - val_loss: 1.6233e-06 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7849e-06 - accuracy: 1.0000 - val_loss: 1.6287e-06 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7426e-06 - accuracy: 1.0000 - val_loss: 2.4372e-06 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8046e-06 - accuracy: 1.0000 - val_loss: 1.5147e-06 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5746e-06 - accuracy: 1.0000 - val_loss: 1.8794e-06 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4825e-06 - accuracy: 1.0000 - val_loss: 1.3372e-06 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5712e-06 - accuracy: 1.0000 - val_loss: 1.0781e-06 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4979e-06 - accuracy: 1.0000 - val_loss: 2.2217e-06 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4398e-06 - accuracy: 1.0000 - val_loss: 9.4893e-07 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3961e-06 - accuracy: 1.0000 - val_loss: 1.7260e-06 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2689e-06 - accuracy: 1.0000 - val_loss: 1.4934e-06 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2802e-06 - accuracy: 1.0000 - val_loss: 1.3424e-06 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2020e-06 - accuracy: 1.0000 - val_loss: 1.3619e-06 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2617e-06 - accuracy: 1.0000 - val_loss: 1.1428e-06 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1376e-06 - accuracy: 1.0000 - val_loss: 9.5840e-07 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0909e-06 - accuracy: 1.0000 - val_loss: 9.1847e-07 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0169e-06 - accuracy: 1.0000 - val_loss: 1.3055e-06 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.5461e-07 - accuracy: 1.0000 - val_loss: 8.4948e-07 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1727e-06 - accuracy: 1.0000 - val_loss: 1.3175e-06 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0252e-06 - accuracy: 1.0000 - val_loss: 9.3138e-07 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.9131e-07 - accuracy: 1.0000 - val_loss: 9.9778e-07 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.3052e-07 - accuracy: 1.0000 - val_loss: 1.1602e-06 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.8008e-07 - accuracy: 1.0000 - val_loss: 7.6542e-07 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.4034e-07 - accuracy: 1.0000 - val_loss: 8.9052e-07 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.3410e-07 - accuracy: 1.0000 - val_loss: 7.1628e-07 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.5408e-07 - accuracy: 1.0000 - val_loss: 6.8656e-07 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.5755e-07 - accuracy: 1.0000 - val_loss: 8.2814e-07 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.9253e-07 - accuracy: 1.0000 - val_loss: 7.7382e-07 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.7851e-07 - accuracy: 1.0000 - val_loss: 7.3057e-07 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.5288e-07 - accuracy: 1.0000 - val_loss: 4.7831e-07 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.6666e-07 - accuracy: 1.0000 - val_loss: 7.7201e-07 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.3641e-07 - accuracy: 1.0000 - val_loss: 7.6759e-07 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.8925e-07 - accuracy: 1.0000 - val_loss: 7.4322e-07 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.7620e-07 - accuracy: 1.0000 - val_loss: 5.2983e-07 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.5439e-07 - accuracy: 1.0000 - val_loss: 6.3561e-07 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.2442e-07 - accuracy: 1.0000 - val_loss: 5.4261e-07 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.2397e-07 - accuracy: 1.0000 - val_loss: 4.8248e-07 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.4007e-07 - accuracy: 1.0000 - val_loss: 4.0038e-07 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.4519e-07 - accuracy: 1.0000 - val_loss: 5.0841e-07 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.7102e-07 - accuracy: 1.0000 - val_loss: 3.9492e-07 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.7481e-07 - accuracy: 1.0000 - val_loss: 5.7137e-07 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.7825e-07 - accuracy: 1.0000 - val_loss: 6.5192e-07 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.2792e-07 - accuracy: 1.0000 - val_loss: 4.4613e-07 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.2200e-07 - accuracy: 1.0000 - val_loss: 3.5307e-07 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.2476e-07 - accuracy: 1.0000 - val_loss: 3.5298e-07 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.3703e-07 - accuracy: 1.0000 - val_loss: 5.8207e-07 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0447e-07 - accuracy: 1.0000 - val_loss: 4.2415e-07 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.4906e-07 - accuracy: 1.0000 - val_loss: 4.0987e-07 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.4994e-07 - accuracy: 1.0000 - val_loss: 3.1516e-07 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.5051e-07 - accuracy: 1.0000 - val_loss: 2.7201e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.3017e-07 - accuracy: 1.0000 - val_loss: 2.8710e-07 - val_accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.2520e-07 - accuracy: 1.0000 - val_loss: 2.5359e-07 - val_accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.2720e-07 - accuracy: 1.0000 - val_loss: 5.1203e-07 - val_accuracy: 1.0000\n",
      "Epoch 222/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0986e-07 - accuracy: 1.0000 - val_loss: 3.2458e-07 - val_accuracy: 1.0000\n",
      "Epoch 223/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.8410e-07 - accuracy: 1.0000 - val_loss: 3.1898e-07 - val_accuracy: 1.0000\n",
      "Epoch 224/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.8394e-07 - accuracy: 1.0000 - val_loss: 4.0220e-07 - val_accuracy: 1.0000\n",
      "Epoch 225/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9770e-07 - accuracy: 1.0000 - val_loss: 4.2623e-07 - val_accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4527e-07 - accuracy: 1.0000 - val_loss: 2.3257e-07 - val_accuracy: 1.0000\n",
      "Epoch 227/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.5672e-07 - accuracy: 1.0000 - val_loss: 2.6514e-07 - val_accuracy: 1.0000\n",
      "Epoch 228/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4528e-07 - accuracy: 1.0000 - val_loss: 3.1983e-07 - val_accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2988e-07 - accuracy: 1.0000 - val_loss: 2.3329e-07 - val_accuracy: 1.0000\n",
      "Epoch 230/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.3271e-07 - accuracy: 1.0000 - val_loss: 2.0135e-07 - val_accuracy: 1.0000\n",
      "Epoch 231/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1378e-07 - accuracy: 1.0000 - val_loss: 2.5025e-07 - val_accuracy: 1.0000\n",
      "Epoch 232/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1186e-07 - accuracy: 1.0000 - val_loss: 2.6846e-07 - val_accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0391e-07 - accuracy: 1.0000 - val_loss: 2.2379e-07 - val_accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9615e-07 - accuracy: 1.0000 - val_loss: 1.8881e-07 - val_accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8683e-07 - accuracy: 1.0000 - val_loss: 1.7018e-07 - val_accuracy: 1.0000\n",
      "Epoch 236/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8620e-07 - accuracy: 1.0000 - val_loss: 1.8311e-07 - val_accuracy: 1.0000\n",
      "Epoch 237/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8078e-07 - accuracy: 1.0000 - val_loss: 1.2539e-07 - val_accuracy: 1.0000\n",
      "Epoch 238/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0401e-07 - accuracy: 1.0000 - val_loss: 2.1508e-07 - val_accuracy: 1.0000\n",
      "Epoch 239/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6423e-07 - accuracy: 1.0000 - val_loss: 1.4594e-07 - val_accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6827e-07 - accuracy: 1.0000 - val_loss: 1.9490e-07 - val_accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5940e-07 - accuracy: 1.0000 - val_loss: 1.5528e-07 - val_accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4914e-07 - accuracy: 1.0000 - val_loss: 1.1498e-07 - val_accuracy: 1.0000\n",
      "Epoch 243/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5346e-07 - accuracy: 1.0000 - val_loss: 1.9189e-07 - val_accuracy: 1.0000\n",
      "Epoch 244/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4148e-07 - accuracy: 1.0000 - val_loss: 1.4439e-07 - val_accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3379e-07 - accuracy: 1.0000 - val_loss: 1.1893e-07 - val_accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3311e-07 - accuracy: 1.0000 - val_loss: 1.4575e-07 - val_accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2545e-07 - accuracy: 1.0000 - val_loss: 1.6459e-07 - val_accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2360e-07 - accuracy: 1.0000 - val_loss: 1.2440e-07 - val_accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1909e-07 - accuracy: 1.0000 - val_loss: 1.4193e-07 - val_accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2046e-07 - accuracy: 1.0000 - val_loss: 1.5568e-07 - val_accuracy: 1.0000\n",
      "Epoch 251/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0805e-07 - accuracy: 1.0000 - val_loss: 9.7264e-08 - val_accuracy: 1.0000\n",
      "Epoch 252/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2556e-07 - accuracy: 1.0000 - val_loss: 1.8768e-07 - val_accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0581e-07 - accuracy: 1.0000 - val_loss: 6.9985e-08 - val_accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0602e-07 - accuracy: 1.0000 - val_loss: 9.9374e-08 - val_accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0012e-07 - accuracy: 1.0000 - val_loss: 9.1435e-08 - val_accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.5969e-08 - accuracy: 1.0000 - val_loss: 1.1100e-07 - val_accuracy: 1.0000\n",
      "Epoch 257/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.3567e-08 - accuracy: 1.0000 - val_loss: 1.2000e-07 - val_accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.3207e-08 - accuracy: 1.0000 - val_loss: 8.4966e-08 - val_accuracy: 1.0000\n",
      "Epoch 259/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.4617e-08 - accuracy: 1.0000 - val_loss: 8.0642e-08 - val_accuracy: 1.0000\n",
      "Epoch 260/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.1288e-08 - accuracy: 1.0000 - val_loss: 9.2042e-08 - val_accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.8246e-08 - accuracy: 1.0000 - val_loss: 6.1013e-08 - val_accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.3849e-08 - accuracy: 1.0000 - val_loss: 1.0084e-07 - val_accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.2343e-08 - accuracy: 1.0000 - val_loss: 9.4370e-08 - val_accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.4337e-08 - accuracy: 1.0000 - val_loss: 7.4670e-08 - val_accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.4358e-08 - accuracy: 1.0000 - val_loss: 8.2876e-08 - val_accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.3100e-08 - accuracy: 1.0000 - val_loss: 7.6129e-08 - val_accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.8242e-08 - accuracy: 1.0000 - val_loss: 7.0058e-08 - val_accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.5172e-08 - accuracy: 1.0000 - val_loss: 7.1844e-08 - val_accuracy: 1.0000\n",
      "Epoch 269/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.6931e-08 - accuracy: 1.0000 - val_loss: 5.9577e-08 - val_accuracy: 1.0000\n",
      "Epoch 270/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.3116e-08 - accuracy: 1.0000 - val_loss: 5.9796e-08 - val_accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.0346e-08 - accuracy: 1.0000 - val_loss: 7.2423e-08 - val_accuracy: 1.0000\n",
      "Epoch 272/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.0550e-08 - accuracy: 1.0000 - val_loss: 7.3717e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.5596e-08 - accuracy: 1.0000 - val_loss: 4.8201e-08 - val_accuracy: 1.0000\n",
      "Epoch 274/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.5878e-08 - accuracy: 1.0000 - val_loss: 8.2751e-08 - val_accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.1064e-08 - accuracy: 1.0000 - val_loss: 5.2989e-08 - val_accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.3214e-08 - accuracy: 1.0000 - val_loss: 5.6383e-08 - val_accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.0989e-08 - accuracy: 1.0000 - val_loss: 5.9081e-08 - val_accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.0974e-08 - accuracy: 1.0000 - val_loss: 7.2891e-08 - val_accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.8567e-08 - accuracy: 1.0000 - val_loss: 3.3852e-08 - val_accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.4634e-08 - accuracy: 1.0000 - val_loss: 8.0968e-08 - val_accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.3298e-08 - accuracy: 1.0000 - val_loss: 4.0607e-08 - val_accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.5304e-08 - accuracy: 1.0000 - val_loss: 4.4092e-08 - val_accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0268e-08 - accuracy: 1.0000 - val_loss: 4.1701e-08 - val_accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0129e-08 - accuracy: 1.0000 - val_loss: 4.8629e-08 - val_accuracy: 1.0000\n",
      "Epoch 285/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0193e-08 - accuracy: 1.0000 - val_loss: 4.7757e-08 - val_accuracy: 1.0000\n",
      "Epoch 286/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.8856e-08 - accuracy: 1.0000 - val_loss: 3.8006e-08 - val_accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.7518e-08 - accuracy: 1.0000 - val_loss: 5.3461e-08 - val_accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.7602e-08 - accuracy: 1.0000 - val_loss: 4.5269e-08 - val_accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.5698e-08 - accuracy: 1.0000 - val_loss: 4.6374e-08 - val_accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.3280e-08 - accuracy: 1.0000 - val_loss: 3.6428e-08 - val_accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.2418e-08 - accuracy: 1.0000 - val_loss: 4.2488e-08 - val_accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0812e-08 - accuracy: 1.0000 - val_loss: 3.2368e-08 - val_accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.2030e-08 - accuracy: 1.0000 - val_loss: 2.7207e-08 - val_accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0594e-08 - accuracy: 1.0000 - val_loss: 4.1052e-08 - val_accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0929e-08 - accuracy: 1.0000 - val_loss: 2.9388e-08 - val_accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9403e-08 - accuracy: 1.0000 - val_loss: 4.5386e-08 - val_accuracy: 1.0000\n",
      "Epoch 297/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9087e-08 - accuracy: 1.0000 - val_loss: 3.6837e-08 - val_accuracy: 1.0000\n",
      "Epoch 298/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.7504e-08 - accuracy: 1.0000 - val_loss: 3.5015e-08 - val_accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4681e-08 - accuracy: 1.0000 - val_loss: 2.6298e-08 - val_accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.5383e-08 - accuracy: 1.0000 - val_loss: 3.5471e-08 - val_accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.6018e-08 - accuracy: 1.0000 - val_loss: 1.5496e-08 - val_accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4770e-08 - accuracy: 1.0000 - val_loss: 3.0240e-08 - val_accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2269e-08 - accuracy: 1.0000 - val_loss: 2.3661e-08 - val_accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4578e-08 - accuracy: 1.0000 - val_loss: 3.0602e-08 - val_accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0607e-08 - accuracy: 1.0000 - val_loss: 1.9120e-08 - val_accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2129e-08 - accuracy: 1.0000 - val_loss: 3.1560e-08 - val_accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0807e-08 - accuracy: 1.0000 - val_loss: 2.8319e-08 - val_accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9336e-08 - accuracy: 1.0000 - val_loss: 2.1317e-08 - val_accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0044e-08 - accuracy: 1.0000 - val_loss: 1.7554e-08 - val_accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9770e-08 - accuracy: 1.0000 - val_loss: 2.5857e-08 - val_accuracy: 1.0000\n",
      "Epoch 311/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7828e-08 - accuracy: 1.0000 - val_loss: 2.0935e-08 - val_accuracy: 1.0000\n",
      "Epoch 312/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7321e-08 - accuracy: 1.0000 - val_loss: 1.8453e-08 - val_accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8709e-08 - accuracy: 1.0000 - val_loss: 2.0417e-08 - val_accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7339e-08 - accuracy: 1.0000 - val_loss: 2.7508e-08 - val_accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6293e-08 - accuracy: 1.0000 - val_loss: 1.9676e-08 - val_accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.5818e-08 - accuracy: 1.0000 - val_loss: 1.8185e-08 - val_accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5768e-08 - accuracy: 1.0000 - val_loss: 1.7153e-08 - val_accuracy: 1.0000\n",
      "Epoch 318/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6262e-08 - accuracy: 1.0000 - val_loss: 1.7413e-08 - val_accuracy: 1.0000\n",
      "Epoch 319/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3940e-08 - accuracy: 1.0000 - val_loss: 1.7032e-08 - val_accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.4126e-08 - accuracy: 1.0000 - val_loss: 1.2217e-08 - val_accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.3855e-08 - accuracy: 1.0000 - val_loss: 1.7214e-08 - val_accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2919e-08 - accuracy: 1.0000 - val_loss: 1.6012e-08 - val_accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2562e-08 - accuracy: 1.0000 - val_loss: 1.4724e-08 - val_accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 1.2627e-08 - accuracy: 1.0000 - val_loss: 1.3979e-08 - val_accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3278e-08 - accuracy: 1.0000 - val_loss: 1.5207e-08 - val_accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1990e-08 - accuracy: 1.0000 - val_loss: 1.1750e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1659e-08 - accuracy: 1.0000 - val_loss: 1.5567e-08 - val_accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1468e-08 - accuracy: 1.0000 - val_loss: 1.1042e-08 - val_accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0687e-08 - accuracy: 1.0000 - val_loss: 1.1348e-08 - val_accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0833e-08 - accuracy: 1.0000 - val_loss: 1.5498e-08 - val_accuracy: 1.0000\n",
      "Epoch 331/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.9783e-09 - accuracy: 1.0000 - val_loss: 1.0769e-08 - val_accuracy: 1.0000\n",
      "Epoch 332/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0688e-08 - accuracy: 1.0000 - val_loss: 1.2455e-08 - val_accuracy: 1.0000\n",
      "Epoch 333/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.7134e-09 - accuracy: 1.0000 - val_loss: 8.8278e-09 - val_accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0044e-08 - accuracy: 1.0000 - val_loss: 1.2309e-08 - val_accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.0121e-09 - accuracy: 1.0000 - val_loss: 6.6809e-09 - val_accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 9.1841e-09 - accuracy: 1.0000 - val_loss: 1.1449e-08 - val_accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.5798e-09 - accuracy: 1.0000 - val_loss: 9.6992e-09 - val_accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.7420e-09 - accuracy: 1.0000 - val_loss: 7.2458e-09 - val_accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.2419e-09 - accuracy: 1.0000 - val_loss: 9.6988e-09 - val_accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.4205e-09 - accuracy: 1.0000 - val_loss: 1.0737e-08 - val_accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.8894e-09 - accuracy: 1.0000 - val_loss: 8.3186e-09 - val_accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 8.4623e-09 - accuracy: 1.0000 - val_loss: 7.8392e-09 - val_accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.3202e-09 - accuracy: 1.0000 - val_loss: 8.4469e-09 - val_accuracy: 1.0000\n",
      "Epoch 344/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.3975e-09 - accuracy: 1.0000 - val_loss: 6.6762e-09 - val_accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.0468e-09 - accuracy: 1.0000 - val_loss: 9.9757e-09 - val_accuracy: 1.0000\n",
      "Epoch 346/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.9095e-09 - accuracy: 1.0000 - val_loss: 7.8622e-09 - val_accuracy: 1.0000\n",
      "Epoch 347/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.7703e-09 - accuracy: 1.0000 - val_loss: 5.5262e-09 - val_accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 7.3944e-09 - accuracy: 1.0000 - val_loss: 6.2089e-09 - val_accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.5444e-09 - accuracy: 1.0000 - val_loss: 7.9787e-09 - val_accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.0608e-09 - accuracy: 1.0000 - val_loss: 6.3646e-09 - val_accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 6.3607e-09 - accuracy: 1.0000 - val_loss: 7.4537e-09 - val_accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 6.0027e-09 - accuracy: 1.0000 - val_loss: 7.7867e-09 - val_accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.8523e-09 - accuracy: 1.0000 - val_loss: 7.2325e-09 - val_accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.8761e-09 - accuracy: 1.0000 - val_loss: 5.7028e-09 - val_accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.6303e-09 - accuracy: 1.0000 - val_loss: 8.4350e-09 - val_accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.6168e-09 - accuracy: 1.0000 - val_loss: 6.2675e-09 - val_accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.2768e-09 - accuracy: 1.0000 - val_loss: 5.7252e-09 - val_accuracy: 1.0000\n",
      "Epoch 358/1000\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 5.2144e-09 - accuracy: 1.0000 - val_loss: 7.7330e-09 - val_accuracy: 1.0000\n",
      "Epoch 359/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 5.2752e-09 - accuracy: 1.0000 - val_loss: 5.1211e-09 - val_accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.9992e-09 - accuracy: 1.0000 - val_loss: 4.7938e-09 - val_accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.7279e-09 - accuracy: 1.0000 - val_loss: 6.1700e-09 - val_accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.7163e-09 - accuracy: 1.0000 - val_loss: 6.9603e-09 - val_accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.6424e-09 - accuracy: 1.0000 - val_loss: 6.4394e-09 - val_accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.4565e-09 - accuracy: 1.0000 - val_loss: 5.9938e-09 - val_accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.5979e-09 - accuracy: 1.0000 - val_loss: 5.1003e-09 - val_accuracy: 1.0000\n",
      "Epoch 366/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.4447e-09 - accuracy: 1.0000 - val_loss: 4.1724e-09 - val_accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.6864e-09 - accuracy: 1.0000 - val_loss: 4.7211e-09 - val_accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0817e-09 - accuracy: 1.0000 - val_loss: 4.1568e-09 - val_accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0529e-09 - accuracy: 1.0000 - val_loss: 5.1599e-09 - val_accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0499e-09 - accuracy: 1.0000 - val_loss: 4.7248e-09 - val_accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.0525e-09 - accuracy: 1.0000 - val_loss: 5.7393e-09 - val_accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 4.1639e-09 - accuracy: 1.0000 - val_loss: 5.7822e-09 - val_accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.8849e-09 - accuracy: 1.0000 - val_loss: 5.3066e-09 - val_accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.7171e-09 - accuracy: 1.0000 - val_loss: 5.1337e-09 - val_accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.5227e-09 - accuracy: 1.0000 - val_loss: 3.6775e-09 - val_accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.5106e-09 - accuracy: 1.0000 - val_loss: 4.5508e-09 - val_accuracy: 1.0000\n",
      "Epoch 377/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.4647e-09 - accuracy: 1.0000 - val_loss: 4.4960e-09 - val_accuracy: 1.0000\n",
      "Epoch 378/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.5013e-09 - accuracy: 1.0000 - val_loss: 6.0912e-09 - val_accuracy: 1.0000\n",
      "Epoch 379/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.4153e-09 - accuracy: 1.0000 - val_loss: 3.3984e-09 - val_accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.2169e-09 - accuracy: 1.0000 - val_loss: 4.8265e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.1150e-09 - accuracy: 1.0000 - val_loss: 4.2026e-09 - val_accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0952e-09 - accuracy: 1.0000 - val_loss: 3.1306e-09 - val_accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 3.0320e-09 - accuracy: 1.0000 - val_loss: 3.5353e-09 - val_accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9569e-09 - accuracy: 1.0000 - val_loss: 2.6842e-09 - val_accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.9063e-09 - accuracy: 1.0000 - val_loss: 3.3979e-09 - val_accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.8484e-09 - accuracy: 1.0000 - val_loss: 3.4290e-09 - val_accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.8457e-09 - accuracy: 1.0000 - val_loss: 3.0382e-09 - val_accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.8032e-09 - accuracy: 1.0000 - val_loss: 2.7230e-09 - val_accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.6790e-09 - accuracy: 1.0000 - val_loss: 3.7709e-09 - val_accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.5751e-09 - accuracy: 1.0000 - val_loss: 3.1689e-09 - val_accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4770e-09 - accuracy: 1.0000 - val_loss: 3.4859e-09 - val_accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.4666e-09 - accuracy: 1.0000 - val_loss: 2.7251e-09 - val_accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.5459e-09 - accuracy: 1.0000 - val_loss: 3.2408e-09 - val_accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.3350e-09 - accuracy: 1.0000 - val_loss: 2.8552e-09 - val_accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2988e-09 - accuracy: 1.0000 - val_loss: 2.7936e-09 - val_accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1407e-09 - accuracy: 1.0000 - val_loss: 2.7935e-09 - val_accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.3271e-09 - accuracy: 1.0000 - val_loss: 3.1151e-09 - val_accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1725e-09 - accuracy: 1.0000 - val_loss: 3.0938e-09 - val_accuracy: 1.0000\n",
      "Epoch 399/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.1547e-09 - accuracy: 1.0000 - val_loss: 2.7961e-09 - val_accuracy: 1.0000\n",
      "Epoch 400/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0963e-09 - accuracy: 1.0000 - val_loss: 2.4053e-09 - val_accuracy: 1.0000\n",
      "Epoch 401/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0864e-09 - accuracy: 1.0000 - val_loss: 2.3454e-09 - val_accuracy: 1.0000\n",
      "Epoch 402/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9833e-09 - accuracy: 1.0000 - val_loss: 3.6185e-09 - val_accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.0385e-09 - accuracy: 1.0000 - val_loss: 2.1452e-09 - val_accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 2.2000e-09 - accuracy: 1.0000 - val_loss: 3.1984e-09 - val_accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.9131e-09 - accuracy: 1.0000 - val_loss: 2.5733e-09 - val_accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8078e-09 - accuracy: 1.0000 - val_loss: 2.4752e-09 - val_accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8416e-09 - accuracy: 1.0000 - val_loss: 2.1983e-09 - val_accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7664e-09 - accuracy: 1.0000 - val_loss: 2.0888e-09 - val_accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7307e-09 - accuracy: 1.0000 - val_loss: 2.4453e-09 - val_accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7021e-09 - accuracy: 1.0000 - val_loss: 2.5806e-09 - val_accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7503e-09 - accuracy: 1.0000 - val_loss: 2.1966e-09 - val_accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.8071e-09 - accuracy: 1.0000 - val_loss: 1.9935e-09 - val_accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.7916e-09 - accuracy: 1.0000 - val_loss: 2.0999e-09 - val_accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6564e-09 - accuracy: 1.0000 - val_loss: 2.7121e-09 - val_accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6889e-09 - accuracy: 1.0000 - val_loss: 2.2678e-09 - val_accuracy: 1.0000\n",
      "Epoch 416/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.5511e-09 - accuracy: 1.0000 - val_loss: 2.6503e-09 - val_accuracy: 1.0000\n",
      "Epoch 417/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6012e-09 - accuracy: 1.0000 - val_loss: 2.2222e-09 - val_accuracy: 1.0000\n",
      "Epoch 418/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4997e-09 - accuracy: 1.0000 - val_loss: 2.1493e-09 - val_accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.6225e-09 - accuracy: 1.0000 - val_loss: 1.4647e-09 - val_accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4291e-09 - accuracy: 1.0000 - val_loss: 2.2505e-09 - val_accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4770e-09 - accuracy: 1.0000 - val_loss: 2.3195e-09 - val_accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4502e-09 - accuracy: 1.0000 - val_loss: 1.9235e-09 - val_accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4975e-09 - accuracy: 1.0000 - val_loss: 2.1012e-09 - val_accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4078e-09 - accuracy: 1.0000 - val_loss: 1.9722e-09 - val_accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3807e-09 - accuracy: 1.0000 - val_loss: 1.8034e-09 - val_accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3665e-09 - accuracy: 1.0000 - val_loss: 2.0347e-09 - val_accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3284e-09 - accuracy: 1.0000 - val_loss: 2.0368e-09 - val_accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3391e-09 - accuracy: 1.0000 - val_loss: 1.9877e-09 - val_accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3405e-09 - accuracy: 1.0000 - val_loss: 1.7449e-09 - val_accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.3011e-09 - accuracy: 1.0000 - val_loss: 1.7863e-09 - val_accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.4129e-09 - accuracy: 1.0000 - val_loss: 2.1608e-09 - val_accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2670e-09 - accuracy: 1.0000 - val_loss: 1.9885e-09 - val_accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2796e-09 - accuracy: 1.0000 - val_loss: 2.2336e-09 - val_accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2913e-09 - accuracy: 1.0000 - val_loss: 2.2783e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2560e-09 - accuracy: 1.0000 - val_loss: 1.8795e-09 - val_accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2058e-09 - accuracy: 1.0000 - val_loss: 1.9041e-09 - val_accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1548e-09 - accuracy: 1.0000 - val_loss: 1.8394e-09 - val_accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.2014e-09 - accuracy: 1.0000 - val_loss: 2.2311e-09 - val_accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.1824e-09 - accuracy: 1.0000 - val_loss: 1.9952e-09 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers, models\n",
    "from keras import Input\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(555)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(search_train_x.shape[1],)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callback_list = [\n",
    "  keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', # 모델의 검증 정확도 모니터링\n",
    "    patience=20, # 1 에포크보다 더 길게 향상되지 않으면 중단\n",
    "  )\n",
    "]\n",
    "# batch_size : batch_size만큼 보고 가중치를 업데이트 주겠다\n",
    "hist = model.fit(search_train_x, search_train_y, epochs=1000, batch_size=10, \n",
    "                 callbacks=callback_list, validation_data=(search_val_x, search_val_y)) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "1SO7Am6Vmipf",
    "outputId": "76fb430f-5f3f-4528-f58c-1939b3cc75d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_20210124.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "plt.plot(acc, 'bo', label='Training acc')\n",
    "plt.plot(val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 849
    },
    "id": "JtjmJJXyoPvZ",
    "outputId": "f4b1bb38-5ccb-482c-fe5c-9c1e4cd3cf9e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2.241536e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>7.841464e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0</td>\n",
       "      <td>3.267214e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>1.050057e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>1.229774e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>1.075968e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "      <td>1.975376e-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     y_predict\n",
       "9        0  2.241536e-11\n",
       "499      0  7.841464e-11\n",
       "891      1  1.000000e+00\n",
       "444      0  3.267214e-10\n",
       "123      0  1.050057e-10\n",
       "..     ...           ...\n",
       "381      0  1.229774e-12\n",
       "580      1  1.000000e+00\n",
       "33       0  1.075968e-09\n",
       "686      1  1.000000e+00\n",
       "410      0  1.975376e-12\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 시각화 함수\n",
    "def learning_graph(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    loss_ax.plot(hist.history['loss'],'g', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'],'b', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "learning_graph(hist)\n",
    "\n",
    "# 실제값, 예측값 그래프\n",
    "y_predict = model.predict(search_test_x) ####\n",
    "\n",
    "# 에러율 - Root Mean Squared Error\n",
    "# rmse = np.sqrt(mean_squared_error(y_predict, search_test_y))\n",
    "# print('RMSE: ',rmse.round(2))\n",
    "\n",
    "# r = explained_variance_score(search_test_y, y_predict)\n",
    "# print('R-Square: ',r.round(2))\n",
    "\n",
    "# fig, loss_ax = plt.subplots()\n",
    "# loss_ax.bar(search_test_y)\n",
    "# loss_ax.bar(y_predict)\n",
    "# loss_ax.legend(loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "df = pd.DataFrame(search_test_y)\n",
    "df.insert(1,'y_predict',y_predict)\n",
    "df.rename(columns={0:'y_test'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동작구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.283237</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture    build1    build2  build3  build4  build5    build6  build7\n",
       "0        0.0  0.000000  0.000000     0.0     0.0   0.125  0.023121    0.00\n",
       "1        0.0  0.214286  0.000000     0.0     1.0   0.125  0.075145    0.25\n",
       "2        0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "3        0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "4        0.0  0.142857  0.000000     0.0     0.0   0.000  0.011561    0.25\n",
       "..       ...       ...       ...     ...     ...     ...       ...     ...\n",
       "131      0.0  0.500000  0.000000     0.0     0.0   0.250  0.283237    0.00\n",
       "132      0.0  0.142857  0.045455     0.0     0.0   0.000  0.375723    0.00\n",
       "133      0.0  0.142857  0.000000     0.0     0.0   0.000  0.115607    0.25\n",
       "134      0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "135      0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "\n",
       "[136 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\dongjak_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>result</th>\n",
       "      <th>result_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.469871e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999471e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.485309e-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>9.952678e-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1.042886e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3.080278e-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture  build1  build2  build3  build4  build5  build6  build7  \\\n",
       "0          0       0       0       0       0       1       4       0   \n",
       "1          0       3       0       0      16       1      13       1   \n",
       "2          0       0       0       0       0       0       0       0   \n",
       "3          0       0       0       0       0       0       0       0   \n",
       "4          0       2       0       0       0       0       2       1   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "131        0       7       0       0       0       2      49       0   \n",
       "132        0       2       1       0       0       0      65       0   \n",
       "133        0       2       0       0       0       0      20       1   \n",
       "134        0       0       0       0       0       0       0       0   \n",
       "135        0       0       0       0       0       0       0       0   \n",
       "\n",
       "           result  result_round  \n",
       "0    1.469871e-09           0.0  \n",
       "1    9.999471e-01           1.0  \n",
       "2    3.575102e-09           0.0  \n",
       "3    3.575102e-09           0.0  \n",
       "4    2.485309e-10           0.0  \n",
       "..            ...           ...  \n",
       "131  9.952678e-12           0.0  \n",
       "132  1.042886e-09           0.0  \n",
       "133  3.080278e-10           0.0  \n",
       "134  3.575102e-09           0.0  \n",
       "135  3.575102e-09           0.0  \n",
       "\n",
       "[136 rows x 10 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charger</th>\n",
       "      <th>destination</th>\n",
       "      <th>population</th>\n",
       "      <th>consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     charger  destination  population  consumer\n",
       "0          0          232         453      1240\n",
       "1          0          232         453      1240\n",
       "2          0          232         453      1240\n",
       "3          0          232         453      1240\n",
       "4          0          232         453      1240\n",
       "..       ...          ...         ...       ...\n",
       "131        1            0         416      2139\n",
       "132        0            0         416      2139\n",
       "133        2            0         416      2139\n",
       "134        0            0         475      2053\n",
       "135        0            0         475      2053\n",
       "\n",
       "[136 rows x 4 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\dongjak_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>charger</th>\n",
       "      <th>destination</th>\n",
       "      <th>population</th>\n",
       "      <th>consumer</th>\n",
       "      <th>result_round</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.469871e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.999471e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.485309e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.952678e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.042886e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.080278e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture  build1  build2  build3  build4  build5  build6  build7  charger  \\\n",
       "0          0       0       0       0       0       1       4       0        0   \n",
       "1          0       3       0       0      16       1      13       1        0   \n",
       "2          0       0       0       0       0       0       0       0        0   \n",
       "3          0       0       0       0       0       0       0       0        0   \n",
       "4          0       2       0       0       0       0       2       1        0   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "131        0       7       0       0       0       2      49       0        1   \n",
       "132        0       2       1       0       0       0      65       0        0   \n",
       "133        0       2       0       0       0       0      20       1        2   \n",
       "134        0       0       0       0       0       0       0       0        0   \n",
       "135        0       0       0       0       0       0       0       0        0   \n",
       "\n",
       "     destination  population  consumer  result_round        result  \n",
       "0            232         453      1240           0.0  1.469871e-09  \n",
       "1            232         453      1240           1.0  9.999471e-01  \n",
       "2            232         453      1240           0.0  3.575102e-09  \n",
       "3            232         453      1240           0.0  3.575102e-09  \n",
       "4            232         453      1240           0.0  2.485309e-10  \n",
       "..           ...         ...       ...           ...           ...  \n",
       "131            0         416      2139           0.0  9.952678e-12  \n",
       "132            0         416      2139           0.0  1.042886e-09  \n",
       "133            0         416      2139           0.0  3.080278e-10  \n",
       "134            0         475      2053           0.0  3.575102e-09  \n",
       "135            0         475      2053           0.0  3.575102e-09  \n",
       "\n",
       "[136 rows x 14 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "                      \n",
    "dong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\flask\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>charger</th>\n",
       "      <th>destination</th>\n",
       "      <th>population</th>\n",
       "      <th>consumer</th>\n",
       "      <th>result_round</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.469871e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.999471e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.485309e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.952678e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.042886e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.080278e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575102e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture  build1  build2  build3  build4  build5  build6  build7  charger  \\\n",
       "0          0       0       0       0       0       1       4       0        0   \n",
       "1          0       3       0       0      16       1      13       1        0   \n",
       "2          0       0       0       0       0       0       0       0        0   \n",
       "3          0       0       0       0       0       0       0       0        0   \n",
       "4          0       2       0       0       0       0       2       1        0   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "131        0       7       0       0       0       2      49       0        1   \n",
       "132        0       2       1       0       0       0      65       0        0   \n",
       "133        0       2       0       0       0       0      20       1        2   \n",
       "134        0       0       0       0       0       0       0       0        0   \n",
       "135        0       0       0       0       0       0       0       0        0   \n",
       "\n",
       "     destination  population  consumer  result_round        result  \n",
       "0            232         453      1240           0.0  1.469871e-09  \n",
       "1            232         453      1240           1.0  9.999471e-01  \n",
       "2            232         453      1240           0.0  3.575102e-09  \n",
       "3            232         453      1240           0.0  3.575102e-09  \n",
       "4            232         453      1240           0.0  2.485309e-10  \n",
       "..           ...         ...       ...           ...           ...  \n",
       "131            0         416      2139           0.0  9.952678e-12  \n",
       "132            0         416      2139           0.0  1.042886e-09  \n",
       "133            0         416      2139           0.0  3.080278e-10  \n",
       "134            0         475      2053           0.0  3.575102e-09  \n",
       "135            0         475      2053           0.0  3.575102e-09  \n",
       "\n",
       "[136 rows x 14 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for j in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][j] != 0:\n",
    "        dong_pred['result_round'][j] = 0\n",
    "            \n",
    "dong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_dongjak.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동대문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\flask\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\dongdaemun_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\dongdaemun_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "                      \n",
    "dong_pred\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    for j in range(len(dong_pred)):\n",
    "        if dong_pred['charger'][j] != 0:\n",
    "            dong_pred['result_round'][j] = 0\n",
    "            \n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_dongdae.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 금천구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\flask\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\guemchon_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\guemchon_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for j in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][j] != 0:\n",
    "        dong_pred['result_round'][j] = 0\n",
    "            \n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_guemchon.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 광진구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\flask\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\gwangjin_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\gwangjin_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    for j in range(len(dong_pred)):\n",
    "        if dong_pred['charger'][j] != 0:\n",
    "            dong_pred['result_round'][j] = 0\n",
    "            \n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_gwangjin.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\flask\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\jung_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\jung_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    for j in range(len(dong_pred)):\n",
    "        if dong_pred['charger'][j] != 0:\n",
    "            dong_pred['result_round'][j] = 0\n",
    "            \n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_jung.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성동구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\flask\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\sungdong_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\sungdong_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    for j in range(len(dong_pred)):\n",
    "        if dong_pred['charger'][j] != 0:\n",
    "            dong_pred['result_round'][j] = 0\n",
    "            \n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_sungdong.csv', encoding='euc-kr')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-flask] *",
   "language": "python",
   "name": "conda-env-.conda-flask-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
